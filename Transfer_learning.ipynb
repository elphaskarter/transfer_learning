{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1Ec34SA-tjHh4pyS3DAFgbc6D7n2lTgP9",
      "authorship_tag": "ABX9TyOsl4NcVMp+i/biDgQ84JC9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elphaskarter/transfer_learning/blob/main/Transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "GokY4_qc1vlk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60535ed6-b426-4e1b-a242-5f459ddb3812"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Accuracy: 0.9381\n",
            "\n",
            "Classification Report:\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "     agricultural       1.00      1.00      1.00        14\n",
            "         airplane       1.00      1.00      1.00         6\n",
            "  baseballdiamond       0.89      0.80      0.84        10\n",
            "            beach       1.00      1.00      1.00        10\n",
            "        buildings       0.80      0.80      0.80        10\n",
            "        chaparral       1.00      1.00      1.00        14\n",
            " denseresidential       0.50      1.00      0.67         4\n",
            "           forest       1.00      1.00      1.00         8\n",
            "          freeway       1.00      1.00      1.00         9\n",
            "       golfcourse       1.00      1.00      1.00        11\n",
            "           harbor       1.00      1.00      1.00        11\n",
            "     intersection       1.00      0.60      0.75         5\n",
            "mediumresidential       0.85      0.79      0.81        14\n",
            "   mobilehomepark       1.00      1.00      1.00        13\n",
            "         overpass       1.00      1.00      1.00         7\n",
            "       parkinglot       1.00      1.00      1.00        11\n",
            "            river       1.00      1.00      1.00        12\n",
            "           runway       1.00      1.00      1.00        10\n",
            "sparseresidential       0.78      1.00      0.88         7\n",
            "     storagetanks       1.00      0.92      0.96        12\n",
            "      tenniscourt       0.82      0.75      0.78        12\n",
            "\n",
            "         accuracy                           0.94       210\n",
            "        macro avg       0.93      0.94      0.93       210\n",
            "     weighted avg       0.95      0.94      0.94       210\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[14  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  6  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  8  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  1]\n",
            " [ 0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  8  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  1]\n",
            " [ 0  0  0  0  0 14  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  8  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  9  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0 11  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0 11  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  1  0  0  0  0  3  1  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  1  0  2  0  0  0  0  0 11  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 13  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  7  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 11  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 12  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 10  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  7  0  0]\n",
            " [ 0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 11  0]\n",
            " [ 0  0  0  0  1  0  0  0  0  0  0  0  1  0  0  0  0  0  1  0  9]]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "def main():\n",
        "    # Mount Google Drive\n",
        "    drive.mount('/content/drive')\n",
        "    data_dir = '/content/drive/MyDrive/Images_Resnet'\n",
        "\n",
        "    # Define transforms\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
        "\n",
        "    # Load dataset and split\n",
        "    dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
        "    train_size = int(0.8 * len(dataset))\n",
        "    val_size = (len(dataset) - train_size) // 2\n",
        "    test_size = len(dataset) - train_size - val_size\n",
        "    train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size],\n",
        "        generator=torch.Generator().manual_seed(42))\n",
        "\n",
        "    # DataLoaders\n",
        "    batch_size = 32\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "    # Load pre-trained ResNet18 and modify\n",
        "    # model = torchvision.models.resnet18(pretrained=True)\n",
        "    # model.fc = torch.nn.Identity()  # Remove classification head\n",
        "    # device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    # model = model.to(device)\n",
        "    # model.eval()\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = torchvision.models.resnet18(weights='DEFAULT')\n",
        "    model.fc = torch.nn.Identity()  # Remove classification head\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    # Feature extraction function\n",
        "    def extract_features(loader):\n",
        "        features, labels = [], []\n",
        "        with torch.no_grad():\n",
        "            for inputs, targets in loader:\n",
        "                inputs = inputs.to(device)\n",
        "                outputs = model(inputs).cpu().numpy()\n",
        "                features.append(outputs)\n",
        "                labels.append(targets.numpy())\n",
        "        return np.concatenate(features), np.concatenate(labels)\n",
        "\n",
        "    # Extract features\n",
        "    train_features, train_labels = extract_features(train_loader)\n",
        "    test_features, test_labels = extract_features(test_loader)\n",
        "\n",
        "    # Train SVM\n",
        "    clf = SVC(kernel='linear', C=1.0)\n",
        "    clf.fit(train_features, train_labels)\n",
        "\n",
        "    # Evaluate\n",
        "    y_pred = clf.predict(test_features)\n",
        "    accuracy = accuracy_score(test_labels, y_pred)\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(test_labels, y_pred, target_names=dataset.classes))\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(confusion_matrix(test_labels, y_pred))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}